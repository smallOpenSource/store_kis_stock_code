import logging
import pandas as pd
from datetime import datetime
import sys
import os

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from .file_analyzer import FileAnalyzer
from .db_validator import DatabaseValidator
from .business_validator import BusinessValidator
from .sample_validator import SampleValidator

logger = logging.getLogger('comprehensive_validator')

class ComprehensiveValidator:
    """í†µí•© ê²€ì¦ ì‹¤í–‰ê¸°"""
    
    def __init__(self):
        self.file_analyzer = FileAnalyzer()
        self.db_validator = DatabaseValidator()
        self.business_validator = BusinessValidator()
        self.sample_validator = SampleValidator()
        self.validation_report = {}
    
    def run_full_validation(self, file_mapping):
        """ì „ì²´ ê²€ì¦ ì‹¤í–‰"""
        logger.info("=" * 60)
        logger.info("KIS ë°ì´í„° í†µí•© ê²€ì¦ ì‹œì‘")
        logger.info("=" * 60)
        start_time = datetime.now()
        
        try:
            # 1. íŒŒì¼ ë¶„ì„
            logger.info("1ï¸âƒ£  ì›ì‹œ íŒŒì¼ ë¶„ì„ ì¤‘...")
            file_stats = self.file_analyzer.analyze_all_files(file_mapping)
            
            # 2. ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë³¸ ê²€ì¦
            logger.info("2ï¸âƒ£  ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë³¸ ê²€ì¦ ì¤‘...")
            db_stats = self.db_validator.count_table_records()
            data_type_checks = self.db_validator.check_data_types()
            integrity_checks = self.db_validator.check_referential_integrity()
            
            # 3. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì¦
            logger.info("3ï¸âƒ£  ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ê²€ì¦ ì¤‘...")
            market_validation, market_distribution = self.business_validator.validate_market_distribution()
            code_format_checks = self.business_validator.validate_code_formats()
            alias_stats = self.business_validator.validate_alias_quality()
            completeness_checks = self.business_validator.validate_data_completeness()
            
            # 4. ìƒ˜í”Œ ë°ì´í„° ê²€ì¦
            logger.info("4ï¸âƒ£  ìƒ˜í”Œ ë°ì´í„° ê²€ì¦ ì¤‘...")
            known_stock_checks = self.sample_validator.validate_known_instruments()
            search_checks = self.sample_validator.validate_search_functionality()
            etf_validation = self.sample_validator.validate_etf_samples()
            market_coverage = self.sample_validator.validate_market_coverage()
            
            # 5. íŒŒì¼ vs DB ë ˆì½”ë“œ ìˆ˜ ë¹„êµ
            logger.info("5ï¸âƒ£  íŒŒì¼-DB ë ˆì½”ë“œ ìˆ˜ ë¹„êµ ì¤‘...")
            count_comparison = self._compare_file_db_counts(file_stats, db_stats)
            
            # ê²€ì¦ ê²°ê³¼ ì¢…í•©
            end_time = datetime.now()
            
            self.validation_report = {
                'metadata': {
                    'timestamp': end_time.isoformat(),
                    'duration': str(end_time - start_time),
                    'validation_version': '1.0'
                },
                'file_analysis': {
                    'file_stats': file_stats,
                    'total_files_analyzed': len(file_stats)
                },
                'database_validation': {
                    'table_stats': db_stats,
                    'data_type_checks': data_type_checks,
                    'integrity_checks': integrity_checks
                },
                'business_validation': {
                    'market_validation': market_validation,
                    'market_distribution': market_distribution,
                    'code_format_checks': code_format_checks,
                    'completeness_checks': completeness_checks,
                    'alias_stats': alias_stats
                },
                'sample_validation': {
                    'known_stock_checks': known_stock_checks,
                    'search_checks': search_checks,
                    'etf_validation': etf_validation,
                    'market_coverage': market_coverage
                },
                'count_comparison': count_comparison,
                'overall_result': self._calculate_overall_result()
            }
            
            # ê²€ì¦ ë¦¬í¬íŠ¸ ì¶œë ¥
            self._print_validation_report()
            
            return self.validation_report
            
        except Exception as e:
            logger.error(f"ê²€ì¦ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            raise
    
    def _compare_file_db_counts(self, file_stats, db_stats):
        """íŒŒì¼ê³¼ DB ë ˆì½”ë“œ ìˆ˜ ë¹„êµ"""
        comparison = {}
        
        # ì¢…ëª©ë³„ ë§¤í•‘
        file_to_db_mapping = {
            'ì½”ìŠ¤í”¼': 'instruments',
            'ì½”ìŠ¤ë‹¥': 'instruments', 
            'ì½”ë„¥ìŠ¤': 'instruments',
            'ELW': 'instruments',
            'íšŒì›ì‚¬ì½”ë“œ': 'member_code',
            'ì—…ì¢…ì½”ë“œ': 'sector_code',
            'í…Œë§ˆì½”ë“œ': 'theme_code'
        }
        
        instruments_total_expected = 0
        instruments_breakdown = {}
        
        for item_name, table_name in file_to_db_mapping.items():
            if item_name in file_stats and file_stats[item_name]['record_count'] is not None:
                file_count = file_stats[item_name]['record_count']
                
                if table_name == 'instruments':
                    instruments_total_expected += file_count
                    instruments_breakdown[item_name] = file_count
                else:
                    db_count = db_stats.get(table_name, 0)
                    
                    # í—ˆìš© ì˜¤ì°¨ ë²”ìœ„ (10% ë˜ëŠ” ìµœì†Œ 5ê°œ)
                    tolerance = max(5, int(file_count * 0.1))
                    is_match = abs(file_count - db_count) <= tolerance
                    
                    comparison[item_name] = {
                        'file_count': file_count,
                        'db_count': db_count,
                        'difference': db_count - file_count,
                        'tolerance': tolerance,
                        'is_match': is_match,
                        'match_percentage': round((min(file_count, db_count) / max(file_count, db_count)) * 100, 2) if max(file_count, db_count) > 0 else 0
                    }
                    
                    if is_match:
                        logger.info(f"âœ“ {item_name}: íŒŒì¼ {file_count:,} vs DB {db_count:,} (ì°¨ì´: {db_count - file_count:+,})")
                    else:
                        logger.warning(f"âœ— {item_name}: íŒŒì¼ {file_count:,} vs DB {db_count:,} (ì°¨ì´: {db_count - file_count:+,}, í—ˆìš©ë²”ìœ„: Â±{tolerance})")
        
        # instruments í…Œì´ë¸” ì „ì²´ ë¹„êµ
        instruments_db_count = db_stats.get('instruments', 0)
        instruments_tolerance = max(50, int(instruments_total_expected * 0.1))
        instruments_match = abs(instruments_total_expected - instruments_db_count) <= instruments_tolerance
        
        comparison['instruments_total'] = {
            'file_count': instruments_total_expected,
            'db_count': instruments_db_count,
            'difference': instruments_db_count - instruments_total_expected,
            'tolerance': instruments_tolerance,
            'is_match': instruments_match,
            'breakdown': instruments_breakdown,
            'match_percentage': round((min(instruments_total_expected, instruments_db_count) / max(instruments_total_expected, instruments_db_count)) * 100, 2) if max(instruments_total_expected, instruments_db_count) > 0 else 0
        }
        
        if instruments_match:
            logger.info(f"âœ“ ì „ì²´ ì¢…ëª©: íŒŒì¼ {instruments_total_expected:,} vs DB {instruments_db_count:,} (ì¼ì¹˜ìœ¨: {comparison['instruments_total']['match_percentage']}%)")
        else:
            logger.warning(f"âœ— ì „ì²´ ì¢…ëª©: íŒŒì¼ {instruments_total_expected:,} vs DB {instruments_db_count:,} (ì°¨ì´: {instruments_db_count - instruments_total_expected:+,})")
        
        return comparison
    
    def _calculate_overall_result(self):
        """ì „ì²´ ê²€ì¦ ê²°ê³¼ ê³„ì‚°"""
        total_checks = 0
        passed_checks = 0
        critical_failures = 0
        
        # ê° ê²€ì¦ í•­ëª©ì˜ ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´íŠ¸
        check_categories = [
            ('database_validation.data_type_checks', True),  # ì¤‘ìš”í•œ ê²€ì‚¬
            ('database_validation.integrity_checks', False),
            ('business_validation.market_validation', True),  # ì¤‘ìš”í•œ ê²€ì‚¬
            ('business_validation.code_format_checks', True),  # ì¤‘ìš”í•œ ê²€ì‚¬
            ('business_validation.completeness_checks', False),
            ('sample_validation.known_stock_checks', True),  # ì¤‘ìš”í•œ ê²€ì‚¬
            ('sample_validation.search_checks', False),
        ]
        
        for category_path, is_critical in check_categories:
            checks = self._get_nested_value(self.validation_report, category_path)
            if checks and isinstance(checks, list):
                for check in checks:
                    total_checks += 1
                    if check.get('result', False):
                        passed_checks += 1
                    elif is_critical:
                        critical_failures += 1
        
        # íŒŒì¼-DB ë¹„êµ ê²°ê³¼ ì¶”ê°€ (ì¤‘ìš”í•œ ê²€ì‚¬)
        if 'count_comparison' in self.validation_report:
            for item, comparison in self.validation_report['count_comparison'].items():
                total_checks += 1
                if comparison.get('is_match', False):
                    passed_checks += 1
                else:
                    critical_failures += 1
        
        # ETF ë° ì‹œì¥ ì»¤ë²„ë¦¬ì§€ ê²€ì¦ ì¶”ê°€
        etf_validation = self._get_nested_value(self.validation_report, 'sample_validation.etf_validation')
        market_coverage = self._get_nested_value(self.validation_report, 'sample_validation.market_coverage')
        
        for validation in [etf_validation, market_coverage]:
            if validation:
                total_checks += 1
                if validation.get('result', False):
                    passed_checks += 1
        
        success_rate = (passed_checks / total_checks * 100) if total_checks > 0 else 0
        
        # ì „ì²´ ìƒíƒœ ê²°ì •
        if critical_failures > 0:
            overall_status = 'CRITICAL_FAIL'
        elif success_rate >= 95:
            overall_status = 'EXCELLENT'
        elif success_rate >= 90:
            overall_status = 'GOOD'
        elif success_rate >= 80:
            overall_status = 'ACCEPTABLE'
        else:
            overall_status = 'FAIL'
        
        return {
            'total_checks': total_checks,
            'passed_checks': passed_checks,
            'failed_checks': total_checks - passed_checks,
            'critical_failures': critical_failures,
            'success_rate': round(success_rate, 2),
            'overall_status': overall_status
        }
    
    def _get_nested_value(self, data, path):
        """ì¤‘ì²©ëœ ë”•ì…”ë„ˆë¦¬ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°"""
        keys = path.split('.')
        for key in keys:
            if isinstance(data, dict) and key in data:
                data = data[key]
            else:
                return None
        return data
    
    def _print_validation_report(self):
        """ê²€ì¦ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        report = self.validation_report
        
        logger.info("\n" + "="*80)
        logger.info("ğŸ” KIS ë°ì´í„° ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸")
        logger.info("="*80)
        
        # ì „ì²´ ê²°ê³¼
        overall = report['overall_result']
        status_emoji = {
            'EXCELLENT': 'ğŸŸ¢',
            'GOOD': 'ğŸ”µ', 
            'ACCEPTABLE': 'ğŸŸ¡',
            'FAIL': 'ğŸ”´',
            'CRITICAL_FAIL': 'âŒ'
        }
        
        logger.info(f"ğŸ“Š ì „ì²´ ìƒíƒœ: {status_emoji.get(overall['overall_status'], 'â“')} {overall['overall_status']}")
        logger.info(f"ğŸ“ˆ ì„±ê³µë¥ : {overall['success_rate']}% ({overall['passed_checks']}/{overall['total_checks']})")
        logger.info(f"â±ï¸  ê²€ì¦ ì‹œê°„: {report['metadata']['duration']}")
        
        if overall['critical_failures'] > 0:
            logger.warning(f"âš ï¸  ì‹¬ê°í•œ ì˜¤ë¥˜: {overall['critical_failures']}ê°œ")
        
        # ë°ì´í„°ë² ì´ìŠ¤ í†µê³„
        logger.info(f"\nğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í†µê³„:")
        for table, count in report['database_validation']['table_stats'].items():
            logger.info(f"  ğŸ“‹ {table}: {count:,}ê°œ")
        
        # ì‹œì¥ë³„ ë¶„í¬
        logger.info(f"\nğŸ“ˆ ì‹œì¥ë³„ ì¢…ëª© ë¶„í¬:")
        market_dist = report['business_validation']['market_distribution']
        for market, types in market_dist.items():
            total_market = sum(types.values())
            logger.info(f"  ğŸ¢ {market}: {total_market:,}ê°œ")
            for inst_type, count in types.items():
                logger.info(f"    â”” {inst_type}: {count:,}ê°œ")
        
        # íŒŒì¼-DB ë¹„êµ ê²°ê³¼
        logger.info(f"\nğŸ”„ íŒŒì¼-DB ë¹„êµ ê²°ê³¼:")
        count_comp = report['count_comparison']
        for item, comp in count_comp.items():
            status = "âœ…" if comp['is_match'] else "âŒ"
            if item == 'instruments_total':
                logger.info(f"  {status} ì „ì²´ ì¢…ëª©: {comp['match_percentage']}% ì¼ì¹˜")
            else:
                logger.info(f"  {status} {item}: {comp['match_percentage']}% ì¼ì¹˜")
        
        # ë³„ì¹­ í†µê³„
        alias_stats = report['business_validation']['alias_stats']
        logger.info(f"\nğŸ·ï¸  ë³„ì¹­ í†µê³„:")
        logger.info(f"  ğŸ“Š ë³„ì¹­ ë³´ìœ ìœ¨: {alias_stats['alias_percentage']}%")
        logger.info(f"  ğŸ“Š í‰ê·  ë³„ì¹­ ìˆ˜: {alias_stats['avg_alias_count']}ê°œ")
        
        # ëŒ€í‘œ ì¢…ëª© ê²€ì¦
        known_checks = report['sample_validation']['known_stock_checks']
        passed_known = sum(1 for check in known_checks if check['result'])
        logger.info(f"\n[TARGET] ëŒ€í‘œ ì¢…ëª© ê²€ì¦: {passed_known}/{len(known_checks)}ê°œ í†µê³¼")
        
        # ì‹¤íŒ¨í•œ ê²€ì¦ í•­ëª© (ìƒìœ„ 10ê°œ)
        failed_checks = self._collect_failed_checks()
        if failed_checks:
            logger.warning(f"\nâŒ ì‹¤íŒ¨í•œ ê²€ì¦ ({len(failed_checks)}ê°œ):")
            for i, check in enumerate(failed_checks[:10], 1):
                logger.warning(f"  {i}. {check}")
            if len(failed_checks) > 10:
                logger.warning(f"  ... ë° {len(failed_checks) - 10}ê°œ ë”")
        else:
            logger.info(f"\nâœ… ëª¨ë“  ê²€ì¦ í†µê³¼!")
        
        logger.info("="*80)
    
    def _collect_failed_checks(self):
        """ì‹¤íŒ¨í•œ ê²€ì¦ í•­ëª© ìˆ˜ì§‘"""
        failed_checks = []
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ ì‹¤íŒ¨ í•­ëª© ìˆ˜ì§‘
        categories = [
            ('database_validation.data_type_checks', 'ë°ì´í„° íƒ€ì…'),
            ('database_validation.integrity_checks', 'ì°¸ì¡° ë¬´ê²°ì„±'),
            ('business_validation.market_validation', 'ì‹œì¥ ë¶„í¬'),
            ('business_validation.code_format_checks', 'ì½”ë“œ í˜•ì‹'),
            ('business_validation.completeness_checks', 'ë°ì´í„° ì™„ì„±ë„'),
            ('sample_validation.known_stock_checks', 'ëŒ€í‘œ ì¢…ëª©'),
            ('sample_validation.search_checks', 'ê²€ìƒ‰ ê¸°ëŠ¥'),
        ]
        
        for category_path, category_name in categories:
            checks = self._get_nested_value(self.validation_report, category_path)
            if checks and isinstance(checks, list):
                for check in checks:
                    if not check.get('result', False):
                        desc = check.get('description', check.get('check', 'ì•Œ ìˆ˜ ì—†ìŒ'))
                        failed_checks.append(f"{category_name}: {desc}")
        
        # íŒŒì¼-DB ë¹„êµ ì‹¤íŒ¨ í•­ëª©
        if 'count_comparison' in self.validation_report:
            for item, comparison in self.validation_report['count_comparison'].items():
                if not comparison.get('is_match', False):
                    failed_checks.append(f"ë ˆì½”ë“œ ìˆ˜ ë¹„êµ: {item} (ì°¨ì´: {comparison.get('difference', 0):+,})")
        
        return failed_checks
    
    def save_report(self, filename='kis_validation_report.json'):
        """ê²€ì¦ ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        import json
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.validation_report, f, ensure_ascii=False, indent=2, default=str)
            logger.info(f"ğŸ“„ ê²€ì¦ ë¦¬í¬íŠ¸ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_summary(self):
        """ê²€ì¦ ê²°ê³¼ ìš”ì•½ ë°˜í™˜"""
        if not self.validation_report:
            return None
            
        overall = self.validation_report['overall_result']
        db_stats = self.validation_report['database_validation']['table_stats']
        
        return {
            'status': overall['overall_status'],
            'success_rate': overall['success_rate'],
            'total_instruments': db_stats.get('instruments', 0),
            'validation_time': self.validation_report['metadata']['duration'],
            'critical_failures': overall['critical_failures']
        }
